{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c08fbd8",
   "metadata": {},
   "source": [
    "# Image Recognition using CNN on CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe5229",
   "metadata": {},
   "source": [
    "In this project we will be using CIFAR-10 dataset. This dataset includes thousands of pictures of 10 different kinds of objects like airplanes, automobiles, birds and so on.\n",
    "\n",
    "Each image in the dataset includes a matching label so we know what kind of image it is.\n",
    "\n",
    "The images in the CIFAR-10 dataset are only 32x32 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304d40ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mohit Tripathi\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25aa8d9",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9845a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test, y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790c28b",
   "metadata": {},
   "source": [
    "Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e998d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train/=255.0\n",
    "X_test/=255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b642a",
   "metadata": {},
   "source": [
    "Convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4879e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631e8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding='same',input_shape=(32,32,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc4756",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f129ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mohit Tripathi\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 15, 15, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               590336    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 642570 (2.45 MB)\n",
      "Trainable params: 642570 (2.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f8c023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 92s 59ms/step - loss: 1.4789 - accuracy: 0.4612 - val_loss: 1.3217 - val_accuracy: 0.5138\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 76s 49ms/step - loss: 1.1675 - accuracy: 0.5836 - val_loss: 0.9721 - val_accuracy: 0.6515\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 1.0303 - accuracy: 0.6377 - val_loss: 0.9128 - val_accuracy: 0.6818\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.9461 - accuracy: 0.6670 - val_loss: 0.8547 - val_accuracy: 0.6968\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 79s 50ms/step - loss: 0.8835 - accuracy: 0.6877 - val_loss: 0.7953 - val_accuracy: 0.7214\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 105s 67ms/step - loss: 0.8476 - accuracy: 0.7020 - val_loss: 0.7707 - val_accuracy: 0.7373\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 89s 57ms/step - loss: 0.8157 - accuracy: 0.7135 - val_loss: 0.7699 - val_accuracy: 0.7403\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.7845 - accuracy: 0.7253 - val_loss: 0.7640 - val_accuracy: 0.7386\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 66s 43ms/step - loss: 0.7597 - accuracy: 0.7326 - val_loss: 0.6993 - val_accuracy: 0.7596\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 88s 56ms/step - loss: 0.7430 - accuracy: 0.7399 - val_loss: 0.7107 - val_accuracy: 0.7571\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 81s 52ms/step - loss: 0.7201 - accuracy: 0.7447 - val_loss: 0.7014 - val_accuracy: 0.7603\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 75s 48ms/step - loss: 0.7071 - accuracy: 0.7529 - val_loss: 0.7474 - val_accuracy: 0.7475\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 76s 49ms/step - loss: 0.6930 - accuracy: 0.7585 - val_loss: 0.6897 - val_accuracy: 0.7661\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 0.6745 - accuracy: 0.7615 - val_loss: 0.7155 - val_accuracy: 0.7538\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.6623 - accuracy: 0.7664 - val_loss: 0.7047 - val_accuracy: 0.7593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25e1d751a30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=15,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e4c46",
   "metadata": {},
   "source": [
    "Save the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c01e1a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6352"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_structure=model.to_json()\n",
    "f=Path(\"model_structure.json\")\n",
    "f.write_text(model_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dd699",
   "metadata": {},
   "source": [
    "Save the trained neural network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67781eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_weight.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dedb5e",
   "metadata": {},
   "source": [
    "Making Predictions on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "656c3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "489d97e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels=[\n",
    "    \"Planes\",\n",
    "    \"car\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Boat\",\n",
    "    \"Truck\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21610354",
   "metadata": {},
   "source": [
    "load the json file that contains the mdoel structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ddc06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=Path(\"model_structure.json\")\n",
    "model_structure=f.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c5ce3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_from_json(model_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec5fb4",
   "metadata": {},
   "source": [
    "reload the model training weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e4d6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model_weight.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09108c9",
   "metadata": {},
   "source": [
    "Load an image file to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e2b943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25e430d4fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "img=load_img(\"dog.png\",target_size=(32,32))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009ed2d",
   "metadata": {},
   "source": [
    "Convert the image to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8e23343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array\n",
    "image_to_test=img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32656f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images=np.expand_dims(image_to_test,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd8b7b",
   "metadata": {},
   "source": [
    "make predictions using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5bfb6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 277ms/step\n"
     ]
    }
   ],
   "source": [
    "results=model.predict(list_of_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f8bc52",
   "metadata": {},
   "source": [
    "since we are only testing one image, we only need to check the first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "246a9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_result=results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16520f7b",
   "metadata": {},
   "source": [
    "We will get a likeliood score for all 10 possible classes. Find out which class has the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "befb52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_class_index=int(np.argmax(single_result))\n",
    "class_likelihood=single_result[most_likely_class_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c2156",
   "metadata": {},
   "source": [
    "Get the name of the most likely class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9f348dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label=class_labels[most_likely_class_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438792a",
   "metadata": {},
   "source": [
    "Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edaaa9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a image is a Dog likelihood: 1.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"This is a image is a {} likelihood: {:2f}\".format(class_label, class_likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dfbd84",
   "metadata": {},
   "source": [
    "# Sentiment Classification using NLP and Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68ef2a",
   "metadata": {},
   "source": [
    "Sentiment Analysis is a means to identofy the view or emotion behind a situation.\n",
    "\n",
    "It basically means to analyse and find the emotion or intent behind a piece of text or speech or any model of communication.\n",
    "\n",
    "This burger has a very bad taste- negative review\n",
    "\n",
    "I ordered this pizza today- nutral sentiment/review\n",
    "\n",
    "I love this cheese sandwich, its so delicious- positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a97f6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c59e44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44541c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09e03df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f84114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"train.txt\",delimiter=\";\",names=['text','label'])\n",
    "df_val=pd.read_csv(\"val.txt\",delimiter=\";\",names=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dddbf34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df_train, df_val])\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ef00104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe:  (18000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17658</th>\n",
       "      <td>i said before i feel like a hypocrite advocati...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13023</th>\n",
       "      <td>i almost feel like i missed this month but whe...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12862</th>\n",
       "      <td>i feel melancholy always the period plus just ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17724</th>\n",
       "      <td>i feel a strange type of peace with this go ar...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>i do meet that i do date will continue to be s...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "17658  i said before i feel like a hypocrite advocati...      love\n",
       "13023  i almost feel like i missed this month but whe...   sadness\n",
       "12862  i feel melancholy always the period plus just ...   sadness\n",
       "17724  i feel a strange type of peace with this go ar...  surprise\n",
       "4878   i do meet that i do date will continue to be s...     anger"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of the dataframe: \",df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4093c3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.countplot(df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c7b3c",
   "metadata": {},
   "source": [
    "Positve Sentiment- joy, love, surprise\n",
    "\n",
    "Negative sentiment- anger, sadness, fear\n",
    "\n",
    "Now we will create a custom encoder to convert categorical target labels to numerical i.e 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3be4062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_encoder(df):\n",
    "    df.replace(to_replace=\"surprise\",value=1, inplace=True)\n",
    "    df.replace(to_replace=\"love\",value=1, inplace=True)\n",
    "    df.replace(to_replace=\"joy\",value=1, inplace=True)\n",
    "    df.replace(to_replace=\"fear\",value=0, inplace=True)\n",
    "    df.replace(to_replace=\"anger\",value=0, inplace=True)\n",
    "    df.replace(to_replace=\"sadness\",value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eec0af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_encoder(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "349c76d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e0b733",
   "metadata": {},
   "source": [
    "Preprocessing Steps\n",
    "\n",
    "Get rid of any characters apart from alphabets\n",
    "\n",
    "Convert the string to lowercase because Python is case-sensitive\n",
    "\n",
    "Check and remove the stopwords\n",
    "\n",
    "Perform lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28a0bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7026340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transformation(df_col):\n",
    "    corpus=[]\n",
    "    for item in df_col:\n",
    "        new_item=re.sub('[^a-zA-Z]',' ',str(item))\n",
    "        new_item=new_item.lower()\n",
    "        new_item=new_item.split()\n",
    "        new_item=[lm.lemmatize(word) for word in new_item if word not in set(stopwords.words('english'))]\n",
    "        corpus.append(' '.join(str(x) for x in new_item))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f9307b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=text_transformation(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba711885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['didnt feel humiliated',\n",
       " 'go feeling hopeless damned hopeful around someone care awake']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ec16069",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2))\n",
    "traindata=cv.fit_transform(corpus)\n",
    "X=traindata\n",
    "y=df.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1b5cb",
   "metadata": {},
   "source": [
    "Now we will fit the data into grid search and view the best parameters using the best_params attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2a9ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'max_features':('auto','sqrt'),\n",
    "            'n_estimators':[5,10],\n",
    "            'max_depth':[10,None],\n",
    "            'min_samples_split':[5],\n",
    "            'min_samples_leaf':[1],\n",
    "            'bootstrap':[True]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71df18cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search=GridSearchCV(RandomForestClassifier(), parameters, cv=5, return_train_score=True,n_jobs=-1)\n",
    "grid_search.fit(X,y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f04a4",
   "metadata": {},
   "source": [
    "We can view all the models and their respective parameters, mean test score and rank as GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e24b1849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 5}\n",
      "Mean test Score:  0.594111111111111\n",
      "Rank:  [8 6 7 5 4 1 3 2]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Mean test Score:  0.618\n",
      "Rank:  [8 6 7 5 4 1 3 2]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 5}\n",
      "Mean test Score:  0.6080555555555556\n",
      "Rank:  [8 6 7 5 4 1 3 2]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Mean test Score:  0.6253333333333334\n",
      "Rank:  [8 6 7 5 4 1 3 2]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 5}\n",
      "Mean test Score:  0.9166666666666666\n",
      "Rank:  [8 6 7 5 4 1 3 2]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Mean test Score:  0.9360000000000002\n",
      "Rank:  [8 6 7 5 4 1 3 2]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 5}\n",
      "Mean test Score:  0.9177777777777777\n",
      "Rank:  [8 6 7 5 4 1 3 2]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Mean test Score:  0.9345555555555555\n",
      "Rank:  [8 6 7 5 4 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print('Parameters: ', grid_search.cv_results_['params'][i])\n",
    "    print('Mean test Score: ',grid_search.cv_results_['mean_test_score'][i])\n",
    "    print(\"Rank: \",grid_search.cv_results_['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43c55d5",
   "metadata": {},
   "source": [
    "Now we will choose the best parameter obtained from GridSearchCV and create a final random forest classifier model and then train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54046810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=5, n_estimators=10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc= RandomForestClassifier(max_features=grid_search.best_params_['max_features'],\n",
    "                           max_depth=grid_search.best_params_['max_depth'],\n",
    "                           n_estimators=grid_search.best_params_['n_estimators'],\n",
    "                           min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                           min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
    "                           bootstrap=grid_search.best_params_['bootstrap'])\n",
    "\n",
    "rfc.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e7c69",
   "metadata": {},
   "source": [
    "Test Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f7aa5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('test.txt',delimiter=';',names=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d304e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test=test_df.text, test_df.label\n",
    "\n",
    "# encode the labels into two classes 0 and 1\n",
    "test_df= custom_encoder(y_test)\n",
    "\n",
    "# preprocessing of text\n",
    "test_corpus=text_transformation(X_test)\n",
    "\n",
    "# convert the text data into vectors\n",
    "testdata=cv.transform(test_corpus)\n",
    "\n",
    "#predict the target\n",
    "predictions=rfc.predict(testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485a1ca",
   "metadata": {},
   "source": [
    "Model Evaluation\n",
    "\n",
    "We will evaluate our model using various metrics such as accuracy score, precision score, recall score confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa07dbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.947\n",
      "Precision Score: 0.9532293986636972\n",
      "Recall Score 0.9304347826086956\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1080\n",
      "           1       0.95      0.93      0.94       920\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.95      0.95      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_score= accuracy_score(y_test, predictions)\n",
    "pre_score= precision_score(y_test, predictions)\n",
    "rec_score=recall_score(y_test, predictions)\n",
    "\n",
    "print('Accuracy Score:',acc_score)\n",
    "print(\"Precision Score:\",pre_score)\n",
    "print('Recall Score',rec_score)\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "cr=classification_report(y_test, predictions)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c38f7",
   "metadata": {},
   "source": [
    "ROC Curve- We will plot probability of the class using the predict_proba() method of random forest classifier and then we will plot the cureve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80238a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_probability= rfc.predict_proba(testdata)\n",
    "fpr,tpr,thresholds=roc_curve(y_test, predictions_probability[:,1])\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0,1])\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f823dd3e",
   "metadata": {},
   "source": [
    "As we cna see that our model performed very well in classifying the sentiments, with an accuracy score, precision score and recall score of approx 96%.\n",
    "\n",
    "Now we will check for custom input as well and let our model identify the sentiment of the input statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ccdd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expression_check(prediction_input):\n",
    "    if prediction_input==0:\n",
    "        print(\"Input statement has negative sentiment\")\n",
    "    elif prediction_input==1:\n",
    "        print(\"Input statement has positive sentiment\")\n",
    "    else:\n",
    "        print(\"Invalid Statement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4916658e",
   "metadata": {},
   "source": [
    "Function to take the input statement and performs the same transformation as we did earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "856a80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predictor(input):\n",
    "    input=text_transformation(input)\n",
    "    transformed_input=cv.transform(input)\n",
    "    prediction=rfc.predict(transformed_input)\n",
    "    expression_check(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7947f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1=[\"Sometimes I just don't want to go out\"]\n",
    "input2=[\"I bought a new phone and it's so good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a33b2da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input statement has negative sentiment\n",
      "Input statement has negative sentiment\n"
     ]
    }
   ],
   "source": [
    "sentiment_predictor(input1)\n",
    "sentiment_predictor(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f5604",
   "metadata": {},
   "source": [
    "# Chatbot using NLP and Neural Networks in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c9c4b",
   "metadata": {},
   "source": [
    "Tag means classes\n",
    "\n",
    "Patterns means what user is going to ask\n",
    "\n",
    "Response is chatbot response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58ddc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"intents\":[\n",
    "    {\"tag\":\"greeting\",\n",
    "     \"patterns\":[\"Hello\",\"How are you?\",\"Hi There\",\"Hi\",\"What's up\"],\n",
    "     \"responses\":[\"Howdy Partner!\",\"Hello\",\"How are you doing?\",\"Greetings!\",\"How do you do\"]\n",
    "        },\n",
    "    {\"tag\":\"age\",\n",
    "     \"patterns\":[\"how old are you\",\"when is your birthday\",\"when was you born\"],\n",
    "     \"responses\":[\"I am 24 years old\",\"I was born in 1966\",\"My birthday is July 3rd and I was born in 1996\",\"03/07/1996\"]\n",
    "        },\n",
    "    {\"tag\":\"date\",\n",
    "     \"patterns\":[\"what are you doing this weekend\",\n",
    "                \"do you want to hangout sometime?\",\"what are your plans for this week\"],\n",
    "     \"responses\":[\"I am available this week\",\"I don't have any plans\",\"I am not busy\"]\n",
    "        },\n",
    "    {\"tag\":\"name\",\n",
    "     \"patterns\":[\"what's your name\",\"what are you called\",\"who are you\"],\n",
    "     \"responses\":[\"My name is Kippi\",\"I'm Kippi\",\"Kippi\"]\n",
    "        },\n",
    "    {\"tag\":\"goodbye\",\n",
    "     \"patterns\":[\"bye\",\"g2g\",\"see ya\",\"adios\",\"cya\"],\n",
    "     \"responses\":[\"It was nice speaking to you\",\"See you later\",\"Speak Soon\"]\n",
    "        },\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102dc54c",
   "metadata": {},
   "source": [
    "For each tag we created, we would specify patterns. Essentially this defines the different ways of how a user may pose a query to the chatbot.\n",
    "\n",
    "The chatbot would then take these patterns and use them as training data to determine what someone is asking and the chatbot response would be relevant to that qustion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a48792ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohit\n",
      "[nltk_data]     Tripathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Mohit\n",
      "[nltk_data]     Tripathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a7aef5",
   "metadata": {},
   "source": [
    "In order to create our training data below steps to be followed\n",
    "\n",
    "Create a vocabulary of all the words used in the patterns\n",
    "\n",
    "Create a list of the classes- tage of ach intent\n",
    "\n",
    "Create a list of all the patterns within the intents file\n",
    "\n",
    "Create a list of all the associated tags to go with each patterns in the intents file.\n",
    "\n",
    "Initialising lemmatier to get stem of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57b9ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "words=[]\n",
    "classes=[]\n",
    "doc_x=[]\n",
    "doc_y=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c7b5b5",
   "metadata": {},
   "source": [
    "Loop through all the intents\n",
    "\n",
    "Tokenize each patter and append token to words, the patterns and the associated tag to their associated list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4984209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        tokens=nltk.word_tokenize(pattern)\n",
    "        words.extend(tokens)\n",
    "        doc_x.append(pattern)\n",
    "        doc_y.append(intent[\"tag\"])\n",
    "    if intent[\"tag\"] not in classes:\n",
    "        classes.append(intent[\"tag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54077e46",
   "metadata": {},
   "source": [
    "Lemmatize all the words in the vocab and convert them to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e830e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953e631",
   "metadata": {},
   "source": [
    "Sorting the vocab and classes in alphabeical order and taking the set to ensure no duplicates occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f6ef978",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=sorted(set(words))\n",
    "classes=sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "22ceae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", 'adios', 'are', 'birthday', 'born', 'bye', 'called', 'cya', 'do', 'doing', 'for', 'g2g', 'hangout', 'hello', 'hi', 'how', 'is', 'name', 'old', 'plan', 'see', 'sometime', 'there', 'this', 'to', 'up', 'wa', 'want', 'week', 'weekend', 'what', 'when', 'who', 'ya', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b689840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'date', 'goodbye', 'greeting', 'name']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1042fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'How are you?', 'Hi There', 'Hi', \"What's up\", 'how old are you', 'when is your birthday', 'when was you born', 'what are you doing this weekend', 'do you want to hangout sometime?', 'what are your plans for this week', \"what's your name\", 'what are you called', 'who are you', 'bye', 'g2g', 'see ya', 'adios', 'cya']\n"
     ]
    }
   ],
   "source": [
    "print(doc_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a4e2e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'age', 'age', 'age', 'date', 'date', 'date', 'name', 'name', 'name', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye']\n"
     ]
    }
   ],
   "source": [
    "print(doc_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95765d8",
   "metadata": {},
   "source": [
    "List for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "23b04678",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=[]\n",
    "out_empty=[0]*len(classes)\n",
    "\n",
    "# creating a bag of words model\n",
    "\n",
    "for idx, doc in enumerate(doc_x):\n",
    "    bow=[]\n",
    "    text=lemmatizer.lemmatize(doc.lower())\n",
    "    for word in words:\n",
    "        bow.append(1) if word in text else bow.append(0)\n",
    "    output_row=list(out_empty)\n",
    "    output_row[classes.index(doc_y[idx])]=1\n",
    "\n",
    "    training.append([bow, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "\n",
    "training=np.array(training,dtype=object)\n",
    "\n",
    "train_X=np.array(list(training[:,0]))\n",
    "train_y=np.array(list(training[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222800f3",
   "metadata": {},
   "source": [
    "The model will look at the features and predict the tagasscoiated with the features and then will select an appropiate message/response from the tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "abdf1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(len(train_X[0]),)\n",
    "output_shape=len(train_y[0])\n",
    "\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "523f479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 128)               4736      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13317 (52.02 KB)\n",
      "Trainable params: 13317 (52.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(output_shape, activation='softmax'))\n",
    "\n",
    "# Create the Adam optimizer with a specified learning rate\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model using the Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e44ebaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.7044 - accuracy: 0.1053\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5705 - accuracy: 0.4211\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4044 - accuracy: 0.5263\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3147 - accuracy: 0.7368\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2359 - accuracy: 0.8421\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0652 - accuracy: 0.8947\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8716 - accuracy: 0.8947\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8219 - accuracy: 0.7895\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8857 - accuracy: 0.7895\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5903 - accuracy: 0.9474\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5231 - accuracy: 0.8421\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4969 - accuracy: 0.7895\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4099 - accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2838 - accuracy: 0.9474\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2675 - accuracy: 0.9474\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1384 - accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1714 - accuracy: 0.8947\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1858 - accuracy: 0.9474\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0734 - accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0854 - accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1283 - accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1000 - accuracy: 0.9474\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0747 - accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0683 - accuracy: 0.9474\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0474 - accuracy: 0.9474\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0682 - accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1934 - accuracy: 0.9474\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0404 - accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1368 - accuracy: 0.9474\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1282 - accuracy: 0.9474\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0469 - accuracy: 0.9474\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0620 - accuracy: 0.9474\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1716 - accuracy: 0.9474\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.7820e-04 - accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3452e-04 - accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0575 - accuracy: 0.9474\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0506 - accuracy: 0.9474\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0787 - accuracy: 0.9474\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0386 - accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1223 - accuracy: 0.9474\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1479e-04 - accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 9.7712e-04 - accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7246e-04 - accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.6214e-04 - accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0542 - accuracy: 0.9474\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.7830e-04 - accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8802e-04 - accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.8878e-04 - accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.3659e-04 - accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2812e-04 - accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9904e-04 - accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.9057e-04 - accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9936e-04 - accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6272e-04 - accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.1276e-04 - accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7015e-05 - accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7309e-04 - accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5005e-04 - accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.7515e-04 - accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4424e-04 - accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.9200e-04 - accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4843e-05 - accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1411e-04 - accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5020e-04 - accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.2126e-04 - accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2040e-05 - accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9226e-04 - accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2900e-04 - accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5658e-04 - accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2862e-04 - accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5902e-05 - accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6608e-04 - accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1120e-04 - accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.4572e-04 - accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3463e-05 - accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.9850e-04 - accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4765e-04 - accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.7900e-04 - accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.9140e-04 - accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5239e-04 - accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9890e-05 - accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1223e-05 - accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.9104e-05 - accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5493e-04 - accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5795e-04 - accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.9178e-04 - accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.3520e-04 - accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0646e-04 - accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.2510e-05 - accuracy: 1.0000\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2098e-04 - accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.7349e-04 - accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.4408e-04 - accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4128e-04 - accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.0480e-04 - accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.7027e-04 - accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.5740e-05 - accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4423e-05 - accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.0364e-04 - accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.3440e-04 - accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.0306e-05 - accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.1523e-04 - accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6135e-05 - accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.0546e-04 - accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2393e-04 - accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.4559e-04 - accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.9756e-04 - accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.8902e-04 - accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.0502e-04 - accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.2717e-05 - accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.5411e-04 - accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5480e-04 - accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.3455e-04 - accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8350e-05 - accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.6965e-04 - accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7017e-04 - accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6588e-04 - accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1443e-04 - accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6867e-04 - accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3809e-04 - accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0605e-04 - accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2665e-04 - accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.0533e-05 - accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9733e-04 - accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4587e-05 - accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.7428e-04 - accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9267e-05 - accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.9486e-04 - accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0266e-04 - accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0672e-05 - accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4343e-04 - accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3383e-05 - accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.8233e-05 - accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0923e-05 - accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.1235e-05 - accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.1816e-04 - accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2143e-04 - accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.9542e-05 - accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.3637e-05 - accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1414e-04 - accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0325e-04 - accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5074e-04 - accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.1704e-05 - accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0547e-04 - accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6139e-06 - accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.1269e-05 - accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.9450e-04 - accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8438e-04 - accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5677e-04 - accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.7065e-05 - accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2687e-04 - accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8494e-04 - accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5573e-04 - accuracy: 1.0000\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.3200e-05 - accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6655e-05 - accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1114e-04 - accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.2265e-04 - accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.2419e-04 - accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0320e-04 - accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1945e-04 - accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7924e-05 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1032e-04 - accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8532e-05 - accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.5450e-05 - accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.0715e-04 - accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.0322e-05 - accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3261e-04 - accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4688e-04 - accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.9840e-04 - accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7366e-04 - accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4988e-04 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5633e-05 - accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.3955e-04 - accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7948e-04 - accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.7668e-04 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.7382e-06 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0885e-05 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3488e-04 - accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1922e-05 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2021e-05 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5519e-04 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5239e-05 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.9090e-05 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3678e-04 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.4938e-05 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0237e-04 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1689e-04 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8683e-05 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.8153e-04 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1067e-05 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7121e-05 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3131e-05 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2712e-06 - accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6618e-04 - accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1802e-05 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.8663e-06 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.4941e-04 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.3322e-05 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.3505e-04 - accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.3130e-06 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.9875e-04 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.0901e-05 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7848e-04 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.0832e-04 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0013e-04 - accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5120e-05 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5667e-04 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.7875e-05 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4234e-05 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0070e-05 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0205e-05 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0312e-05 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4919e-05 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.2287e-04 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.4875e-04 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.3256e-06 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.7966e-05 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.8175e-05 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5487e-06 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.0131e-05 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2809e-04 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0375e-05 - accuracy: 1.0000\n",
      "Epoch 321/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step - loss: 7.4481e-05 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3440e-04 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.2050e-06 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.9614e-06 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.7268e-06 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4561e-05 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.8234e-06 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.0241e-06 - accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.0553e-04 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3110e-04 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4490e-04 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.4741e-05 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0419 - accuracy: 0.9474\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.3392e-06 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4450e-04 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9731e-05 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2314e-04 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.9188e-06 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.6692e-04 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.6158e-04 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.3319e-04 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.1360e-06 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.5498e-05 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6852e-04 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.3810e-04 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.7010e-04 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.0657e-05 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3281e-05 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3762e-04 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.2287e-06 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3060e-05 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8626e-05 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2378e-05 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.3271e-05 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.2415e-06 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3069e-05 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0384e-05 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8397e-06 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4551e-05 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3294e-05 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4097e-05 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8696e-04 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.8667e-04 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9443e-04 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0372e-04 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3100e-04 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0516 - accuracy: 0.9474\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4697e-05 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0420 - accuracy: 0.9474\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2858e-04 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7606e-06 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.5915e-05 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4666e-05 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1030e-05 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9693e-05 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.9417e-05 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3531e-06 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8884e-04 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.0569e-06 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6540e-06 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.2076e-07 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.5657e-04 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.7924e-05 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5051e-05 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.4034e-06 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6678e-06 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.9979e-06 - accuracy: 1.0000\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.7607e-05 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7712e-04 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4164e-04 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9144e-04 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0990e-05 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4256e-06 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8414e-04 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0201e-05 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9627e-06 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.6312e-04 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.1827e-05 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.5926e-06 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.9054e-07 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.9451e-05 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9439e-06 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1370e-06 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7818e-06 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4417e-04 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1409e-04 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7711e-04 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7295e-04 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3236e-05 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9499e-04 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9372e-05 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9228e-04 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.7821e-06 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.4317e-04 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3082e-05 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.3577e-04 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.2858e-04 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1684e-06 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6901e-05 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1043e-06 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.0633e-05 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5075e-04 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.9408e-04 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5632e-04 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0031e-04 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2654e-04 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.4274e-05 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.0309e-07 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0733e-04 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.5112e-04 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.7796e-05 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.8861e-06 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.4838e-05 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1933e-05 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9016e-07 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.2992e-05 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.3330e-04 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8949e-04 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.4158e-05 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1248e-04 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4890e-04 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1740e-05 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2002e-05 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6233e-05 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4260e-05 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.4783e-06 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2592e-05 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.6378e-05 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3664e-05 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.9636e-04 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3338e-05 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7456e-04 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.1636e-06 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1414e-05 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7494e-04 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6086e-05 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0560 - accuracy: 0.9474\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0521e-05 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3062e-05 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1298e-04 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9136e-06 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9814e-05 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7458e-05 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3187e-05 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0256e-05 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1285e-05 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0961 - accuracy: 0.9474\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0271e-07 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1345e-06 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2356e-04 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1443e-05 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.5987e-04 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7345e-04 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1960e-07 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25e2574d310>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_X, y=train_y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a404dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokens=nltk.word_tokenize(text)\n",
    "    tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "def bag_of_words(text,vocab):\n",
    "    tokens=clean_text(text)\n",
    "    bow=[0]*len(vocab)\n",
    "    for w in tokens:\n",
    "        for idx, word in enumerate(vocab):\n",
    "            if word==w:\n",
    "                bow[idx]=1\n",
    "    return np.array(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "605acc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_class(text, vocab,labels):\n",
    "    bow=bag_of_words(text, vocab)\n",
    "    result=model.predict(np.array([bow]))[0]\n",
    "    thresh=0.2\n",
    "    y_pred=[[idx,res] for idx, res in enumerate(result) if res>thresh]\n",
    "\n",
    "    y_pred.sort(key=lambda x:x[1], reverse=True)\n",
    "    return_list=[]\n",
    "    for r in y_pred:\n",
    "        return_list.append(labels[r[0]])\n",
    "    return return_list\n",
    "\n",
    "def get_response(intents_list, intents_json):\n",
    "    tag=intents_list[0]\n",
    "    list_of_intents=intents_json[\"intents\"]\n",
    "    for i in list_of_intents:\n",
    "        if i[\"tag\"]==tag:\n",
    "            result=random.choice(i[\"responses\"])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d0c9e",
   "metadata": {},
   "source": [
    "Running the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7381a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Hello\n",
      "what is your name\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "I'm Kippi\n",
      "goodbye\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "How do you do\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message=input(\"\")\n",
    "    intents=pred_class(message, words, classes)\n",
    "    result=get_response(intents,data)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13cd9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
